---
layout: page
title: Deep Speech Translation Model
description: A multi-head attention Seq2Seq LSTM model for English audio transcription
img: assets/img/transformer.png
importance: 2
category: work
---

• Created a LSTM deep learning model for transcription of raw Mel Frequency Cepstral Coefficients (MFCC) audio

• Implemented multi-head attention mechanism to improve the model’s ability to capture long-term dependencies

• Used cosine annealing scheduling, Gumbel-noise re-parametrization, and Locked Dropout optimization technique to prevent over-fitting and improve validation accuracy